# Dataset 2 — Barchart  
R scripts for rolling-window GJR–GARCH variance forecasting on high-frequency FX (BarChart) data.

---

## Overview
This folder contains the code used to generate the **Dataset 2** results in the thesis (USDEUR 1-minute base data aggregated to 5m/15m/30m/60m). It covers:

- Baseline one-step forecast diagnostics under different innovation assumptions (Normal vs Student-t with ν estimated / fixed).  
- Multi-horizon variance forecasting with **end-aligned** origins (5m, 15m, 30m, 60m horizons) and hourly refits.  
- Summary table builders for the 200-minute baseline.  
- Data aggregation from 1-minute to higher frequencies.  
- (DM tests are produced by the separate “every-bin, multi-window” runners; see note below.)

---

## Data expectations
- Input CSVs named like `USDEUR1M.csv`, `USDEUR5M.csv`, `USDEUR15M.csv`, `USDEUR30M.csv`, `USDEUR60M.csv`.  
- Schema (per row):  
  `pair, bin_start, bin_end, bin, n_1m, expected_n, log_return`  
- Scripts **filter to complete bins** via `n_1m == expected_n` and use `bin_end` as the timestamp (UTC).  
- Period of analysis: **2025-01-01 00:00 UTC → 2025-09-01 00:00 UTC** (two-month rolling test windows).

---

## Key scripts and what they produce

### A) One-step baseline diagnostics (Table 5.11–5.14)
- **`RollingGJRGARCHrefitafter1hourNormDistribution.R`**  
  GJR–GARCH(1,1) with **Normal** innovations. Refit hourly with a **200-obs** window on the 1-minute series.  
  **Thesis mapping:** Table **5.11**.

- **`UpdatedRollingGJRGARCHrefitafter1hourTdistEstimated.R`**  
  GJR–GARCH(1,1) with **Student-t, ν estimated (MLE)**. Same refit logic as above.  
  **Thesis mapping:** Table **5.12**.

- **`UpdatedRollingGJRGARCHrefitafter1hourTdist20df.R`**  
  Student-t with **ν = 20 fixed**.  
  **Thesis mapping:** Table **5.13**.

- **`UpdatedRollingGJRGARCHrefitafter1hourTdist.R`**  
  Student-t with **ν = 10 fixed** (selected spec).  
  **Thesis mapping:** Table **5.14**.

Each script saves per-period summaries and (optionally) details CSVs for the baseline one-step comparison.

---

### B) Multi-horizon (end-aligned) baseline, 200-minute window
- **`200WindowSizeFixedMultiStepForAllFrequencies.R`**  
  Fixed **ν = 10**; runs **multi-horizon** variance forecasts with **end-aligned** origins across 1m/5m/15m/30m/60m.  
  Hourly refits; training history ≈ **200 minutes** (window bins vary by frequency to match ~200 minutes).  
  **Outputs:** one CSV per (frequency, horizon) with:
  - `summary.*` metrics on **H-step aggregated** variance (MSE/MAE/RMSE/QLIKE/Quasi-Deviance), counts, coverage  
  - `details.*` rows containing **per-step** σ² forecasts and r² actuals

- **`SummaryTables200windowsize.R`**  
  Collates the above outputs into the **Section 5.2** tables/figures (baseline multi-horizon, 200-minute window).

**Note:** The **Diebold–Mariano (DM)** comparisons in the main text and Appendix D were generated by the *end-aligned, every-bin, multi-window (50/100/200)* runners that write to  
`results/<runid>/w{50|100|200}/test_<freqtag>_<H>step.csv`.  
Those scripts live alongside (two variants: a simple serial runner and a parallel per-period runner).

---

### C) Data prep & helpers
- **`Aggregating1minuteintervalsto5_15and60Minutes.R`**  
  Builds 5m/15m/60m series from the 1m base, enforcing **complete-bin** alignment and computing `log_return`.

- **`ToCheckIfJointOrTwoStage.R`**  
  Quick checker to verify **end-aligned** (joint) vs two-stage aggregation logic. Used for validation, not a final output.

- **`barchart_multipair_ct_2015New.py`**  
  BarChart download helper for multi-pair 1-minute data (only needed if you need to (re)download).

- **`README.md`**  
  This file.

---

## Common settings (used throughout)
- Model: **GJR–GARCH(1,1)** with zero mean (`armaOrder = c(0,0), include.mean = FALSE`).  
- Refit cadence: **hourly**.  
- Training history: **~200 minutes** for baseline (window bins vary by frequency).  
- Periodization: rolling **two-month** test windows from 2025-01-01.  
- Coverage: 95% bands use Normal or standardized-t quantiles consistent with the innovation assumption.

---

## Typical run order

1. **Ensure data present**  
   - Place `USDEUR1M.csv` (and aggregated 5m/15m/30m/60m if already built) in the working directory.  
   - Or run `Aggregating1minuteintervalsto5_15and60Minutes.R` to create higher-frequency series from 1m.

2. **Baseline one-step diagnostics**  
   - Run the four scripts for Normal / t(ν̂) / t(20) / t(10) to produce the per-period summaries for **Tables 5.11–5.14**.

3. **Multi-horizon baseline (200-minute)**  
   - Run `200WindowSizeFixedMultiStepForAllFrequencies.R`.  
   - Then run `SummaryTables200windowsize.R` to collate results.

4. **(Optional) DM comparisons**  
   - Use the *every-bin, end-aligned, multi-window (50/100/200)* runners (kept alongside) to write  
     `results/<runid>/w{50|100|200}/test_<freqtag>_<H>step.csv`, then compute DM stats for the main text and Appendix D.

---

## Repro tips
- Set a seed (already done inside scripts) for reproducible multi-start `gosolnp` fits.  
- Ensure system timezone is UTC or let the scripts force UTC when parsing timestamps.  
- The scripts drop incomplete bins and non-finite returns by design; expect occasional skipped periods if data are sparse.

---

## Questions?
If you’re re-running results or extending the experiments (other pairs, different ν, alternative windows), start from the A/B blocks above and then add the DM runner sweep.

